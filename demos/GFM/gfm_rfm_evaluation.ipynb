{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Observed Flood Extent from the GFM against Forecast Flood Extent from the EFAS Rapid Flood Mapping layer\n",
    "\n",
    "With this notebook, we show how to use the new GFM STAC service to\n",
    "derive the maximum flood extent for a flood event, extract the corresponding\n",
    "forecast product from the EFAS Rapid Flood Mapping layer and perform\n",
    "a simple evaluation.\n",
    "\n",
    "This example notebook is structured as follows:\n",
    "\n",
    "0. (Import and install the necessary python packages)\n",
    "1. Download data from the GFM STAC service (ensemble flood extent, reference water, exclusion mask)\n",
    "2. Download the EFAS Rapid Flood Mapping data\n",
    "3. Evaluate EFAS layer against the GFM data - exclude areas either within reference water mask or exclusion masks\n",
    "\n",
    "We present an example analysis of the flooding that occurred in south-west \n",
    "Poland between the 18th - 28th September 2024\n",
    "\n",
    "Please note you must have an EFAS account to access the data used in\n",
    "this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Some necessary imports\n",
    "\n",
    "from pystac_client import Client\n",
    "from datetime import datetime\n",
    "from odc import stac as odc_stac\n",
    "import pyproj\n",
    "import rioxarray # noqa\n",
    "import xarray as xr\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Observed Flood Extent Data using the GFM STAC service\n",
    "\n",
    "Firstly define the GFM product you wish to download.\n",
    "\n",
    "Then define a time range of interest and the coordinates of the area of\n",
    "interest (aoi).\n",
    "\n",
    "These parameters are passed to the GFM STAC service to find the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounding box (West, South, East, North)\n",
    "aoi = box(16.77, 49.91, 18.62, 51.25)\n",
    "\n",
    "# Define time range\n",
    "time_range = (datetime(2024, 9, 18), datetime(2024, 9, 28))\n",
    "\n",
    "# EODC STAC API URL\n",
    "api_url = \"https://stac.eodc.eu/api/v1\"\n",
    "eodc_catalog = Client.open(api_url)\n",
    "\n",
    "# Define search query using pystac_client\n",
    "search = eodc_catalog.search(\n",
    "    max_items=1000,\n",
    "    collections=\"GFM\",\n",
    "    intersects=aoi,\n",
    "    datetime=time_range\n",
    ")\n",
    "\n",
    "# Get all found items\n",
    "items = search.item_collection()\n",
    "print(\"We found\", len(items), \"items, that match our filter criteria.\")\n",
    "\n",
    "# Retrieve the CRS from one of the found items\n",
    "crs_equi7 = pyproj.CRS.from_wkt(items[0].properties[\"proj:wkt2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the returned data are loaded into an xarray dataset in the Equi7Grid projection.\n",
    "Additionally, the sum over the time dimension is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the asset names you want to use \n",
    "asset_names = [\"ensemble_flood_extent\", \"reference_water_mask\", \"exclusion_mask\"]\n",
    "\n",
    "# By setting chunks, the odc library \"lazy loads\" the data. -1 for time means\n",
    "# that all time steps are included in one chunk. Reduce the chunk size for x\n",
    "# and/or y if your kernel crashes due to out of memory issues\n",
    "xx = odc_stac.load(\n",
    "    items, \n",
    "    bbox=aoi.bounds,\n",
    "    crs=crs_equi7,\n",
    "    bands=asset_names,\n",
    "    dtype=\"uint8\",\n",
    "    chunks={\"x\": 2000, \"y\": 2000, \"time\": -1}, \n",
    "    resolution=20)\n",
    "\n",
    "# Only include data which is not nodata and not 0\n",
    "nodata = 255\n",
    "xx = xx.where((xx != nodata) & (xx != 0))\n",
    "\n",
    "# Create the sum over the time dimension\n",
    "# This is done for all specified assets\n",
    "data = xx.sum(dim=\"time\").astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell is loaded, we advise to save the data on disk for later use.\n",
    "With that, you do not need to download the same data everytime you start this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Save the \"raw\" data as ZARR data store for later use\n",
    "# xx.to_zarr(\"./gfm_data.zarr\")\n",
    "\n",
    "# Read data from ZARR data store once saved\n",
    "# xx = xr.open_zarr(\"./gfm_data.zarr\")\n",
    "\n",
    "# ZARR is currently not writing CRSs into data stores. Add it again after\n",
    "# opening the data store\n",
    "# xx.rio.write_crs(crs_equi7, inplace=True)\n",
    "\n",
    "# nodata = 255\n",
    "\n",
    "# Create the sum over the time dimension\n",
    "# This is done for all specified assets\n",
    "# data = xx.sum(dim=\"time\").astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set valid values to 1 for each individual layer and save it as GTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract maximum flood extent\n",
    "data[\"ensemble_flood_extent\"] = data[\"ensemble_flood_extent\"].where((data[\"ensemble_flood_extent\"] < 1) | (data[\"ensemble_flood_extent\"] > nodata), 1)\n",
    "\n",
    "# Reference water mask\n",
    "data[\"reference_water_mask\"] = data[\"reference_water_mask\"].where((data[\"reference_water_mask\"] < 1) | (data[\"reference_water_mask\"]  > nodata), 1)\n",
    "\n",
    "# # Exclusion mask\n",
    "data[\"exclusion_mask\"] = data[\"exclusion_mask\"].where((data[\"exclusion_mask\"] < 1) | (data[\"exclusion_mask\"] > nodata), 1)\n",
    "\n",
    "# Save as Raster in Equi7Grid\n",
    "data[\"ensemble_flood_extent\"].rio.to_raster(\"ensemble_flood_extent_equi7.tif\", compress=\"LZW\")\n",
    "data[\"reference_water_mask\"].rio.to_raster(\"reference_water_mask_equi7.tif\", compress=\"LZW\")\n",
    "data[\"exclusion_mask\"].rio.to_raster(\"exclusion_mask_equi7.tif\", compress=\"LZW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounding coordinates of the GFM data\n",
    "dx = data.x.values[1]-data.x.values[0]\n",
    "dy = data.y.values[1]-data.y.values[0]\n",
    "\n",
    "xmin = data.x.values.min() - (dx/2)\n",
    "xmax = data.x.values.max() + (dy/2)\n",
    "\n",
    "ymin = data.y.values.min() - abs(dy/2)\n",
    "ymax = data.y.values.max() + abs(dy/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Forecasted Flood Extent from the EFAS Rapid Flood Mapping layer\n",
    "\n",
    "Specify the date of the forecast for which you wish to retrieve data. You\n",
    "will also need to retrieve your efas web token, which you can generate by\n",
    "logging in to this website https://european-flood.emergency.copernicus.eu/en/efas-web-services\n",
    "and copying the web token shown in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcast_date = '2024091800'  # date of the forecast as string in YYYYMMDDHH format\n",
    "efas_token = 'your_efas_token'  # generate token at https://european-flood.emergency.copernicus.eu/en/efas-web-services\n",
    "#                                                the token needs to be regenerated after every use!\n",
    "\n",
    "url_rfm = f'https://european-flood.emergency.copernicus.eu/api/fms/download/efas/RapidFloodMapping/{fcast_date[0:4]}-{fcast_date[4:6]}-{fcast_date[6:8]}T{fcast_date[8:10]}:00Z?token={efas_token}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the forecast flood extent file from the EFAS website, load it in then clip to AOI\n",
    "\n",
    "This will save a zip file into the same folder where you have saved\n",
    "this notebook. An ESRI shapefile containing the forecast flood \n",
    "extent will be extracted from this zip file into the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url_rfm)\n",
    "out_zip = f'RFM_{fcast_date}.zip'\n",
    "with open(out_zip, 'wb') as file:\n",
    "  file.write(response.content)\n",
    "\n",
    "with ZipFile(out_zip, 'r') as zip_ref:\n",
    "  zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Forecasted Flood Extent file\n",
    "\n",
    "The forecast flood extent shapefile is loaded as a GeoPandas\n",
    "GeoDataFrame. It is then clipped to the extent of the aoi \n",
    "which you defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rfm_file = f'FloodMask{fcast_date}.shp'\n",
    "rfm_data = gpd.read_file(rfm_file)\n",
    "\n",
    "# Clip the Rapid Flood Mapping to your drawn area\n",
    "rfm_intersect = gpd.clip(rfm_data, gpd.GeoDataFrame(index=[0], crs='epsg:4326', geometry=[aoi]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare GFM and RFM Data\n",
    "\n",
    "In this part the observed flood extent from the GFM and forecast\n",
    "flood extent from EFAS are compared to identify areas of agreement\n",
    "and disagreement.\n",
    "\n",
    "#### Firstly convert the Forecast Flood Extent file from an ESRI Shapefile into a grid\n",
    "\n",
    "We use rasterio.rasterize() to convert the shapefile onto the same grid as the\n",
    "GFM maximum flood extent which we re-projected onto the Equi7Grid projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfm_flood = data[\"ensemble_flood_extent\"].values\n",
    "\n",
    "transform = from_bounds(xmin, ymin, xmax, ymax, gfm_flood.shape[1], gfm_flood.shape[0])\n",
    "\n",
    "rfm_intersect_equi7 = rfm_intersect.to_crs(crs_equi7)\n",
    "\n",
    "# Get geometry and corresponding value from the GeoDataFrame\n",
    "shapes = ((geom, 1) for geom in rfm_intersect_equi7.geometry)\n",
    "\n",
    "# Rasterize the geometries into the numpy array\n",
    "rfm_raster = rasterize(\n",
    "    shapes,\n",
    "    out_shape=gfm_flood.shape,\n",
    "    transform=transform,\n",
    "    fill=0, \n",
    "    dtype=np.uint8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the Observed and Forecast Flood Extent Grids\n",
    "\n",
    "Use a contingency table approach to classify each grid cell as one of the following:\n",
    "1. Hit - where flooding is present in both the GFM & EFAS forecast\n",
    "2. False alarm - flooding only present in the EFAS forecast\n",
    "3. Miss - flooding only present in the GFM observations\n",
    "4. Correct negative - no flooding present in either GFM or EFAS data\n",
    "\n",
    "We exclude areas which are either a) in the reference water mask, or b) in the exclusion mask\n",
    "\n",
    "From this classification, we compute the following performance scores:\n",
    "1. CSI (Critical Success Index), range 0-1 where 1 = perfect agreement between forecast and observations\n",
    "2. False Alarm Ration, range 0-1 where 0 is optimal, shows the fraction of grid cells which were forecasted as being flooded which were incorrect\n",
    "3. Hit Rate, range 0-1 where 1 is optimal, shows the fraction of observed flooded grid cells which were correctly forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare GFM and RFM data\n",
    "\n",
    "gfm_rwm = data[\"reference_water_mask\"].values\n",
    "gfm_em = data[\"exclusion_mask\"].values\n",
    "\n",
    "# compute the total number of hits, false alarms, misses and correct negatives\n",
    "tp = np.where((gfm_flood == 1) & (rfm_raster == 1) & (gfm_rwm < 1) & (gfm_em == 0))[0].shape[0] # hits\n",
    "fp = np.where((gfm_flood == 0) & (rfm_raster == 1) & (gfm_rwm < 1) & (gfm_em == 0))[0].shape[0] # false alarms\n",
    "fn = np.where((gfm_flood == 1) & (rfm_raster == 0) & (gfm_rwm < 1) & (gfm_em == 0))[0].shape[0] # misses\n",
    "tn = np.where((gfm_flood == 0) & (rfm_raster == 0) & (gfm_rwm < 1) & (gfm_em == 0))[0].shape[0] # correct negatives\n",
    "\n",
    "csi = (tp / (tp + fp + fn))  # critical success index (CSI)\n",
    "far = (fp / (tp + fp))  # false alarm ration (FAR)\n",
    "hr = (tp / (tp + fn))  # hit rate (HR)\n",
    "\n",
    "print(f'CSI: {\"%.2f\" % csi}')\n",
    "print(f'False Alarm Ratio: {\"%.2f\" % far}')\n",
    "print(f'Hit Rate: {\"%.2f\" % hr}')\n",
    "\n",
    "# Create a grid for the evaluation results to show on a map\n",
    "# create a new grid which shows whether each grid cell is a hit, false alarm or miss\n",
    "eval_grid = np.zeros(gfm_flood.shape, dtype=np.uint8)\n",
    "eval_grid[(gfm_flood == 1) & (rfm_raster == 1) & (gfm_rwm < 1) & (gfm_em ==0)] = 1  # Hits\n",
    "eval_grid[(gfm_flood == 1) & (rfm_raster == 0) & (gfm_rwm < 1) & (gfm_em ==0)] = 2  # Misses\n",
    "eval_grid[(gfm_flood == 0) & (rfm_raster == 1) & (gfm_rwm < 1) & (gfm_em ==0)] = 3  # False alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RFM data as raster\n",
    "with rasterio.open('./rfm_data_equi7.tif', 'w', driver='GTiff', height=rfm_raster.shape[0],\n",
    "                   width=rfm_raster.shape[1], count=1, dtype=rfm_raster.dtype,\n",
    "                   crs=crs_equi7, transform=transform, compress=\"LZW\") as dst:\n",
    "    dst.write(rfm_raster, 1)\n",
    "\n",
    "# Save RFM GFM evaluation results as raster\n",
    "with rasterio.open('./rfm_gfm_eval_equi7.tif', 'w', driver='GTiff', height=eval_grid.shape[0],\n",
    "                   width=eval_grid.shape[1], count=1, dtype=eval_grid.dtype,\n",
    "                   crs=crs_equi7, transform=transform, compress=\"LZW\") as dst:\n",
    "    dst.write(eval_grid, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook shows how you can download specific GFM data \n",
    "using the GFM STAC service and the EFAS Rapid Flood Mapping forecast \n",
    "layer and compare the data, with the idea of evaluating the \n",
    "performance of the forecast layer.\n",
    "\n",
    "In general it could be seen that:\n",
    "* The forecasted inundation extent generally over-predicted when compared to GFM\n",
    "* Because forecast data is coarser resolution\n",
    "    * Smoothed representation of floodplain topography, e.g. doesn't represent levees\n",
    "* Therefore you need to be careful regarding the precision for which the forecast information can be used\n",
    "    * It can highlight general floodplain areas at risk but be careful when identifying specific towns/cities affected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eodc_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
