{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Story: Load Data\n",
    "\n",
    "https://eodc.atlassian.net/browse/SDO2024-307\n",
    "\n",
    "Loading your user-collections is a simple process, in order to ensure this notebook works, make sure to already have results of a job saved\n",
    "in your workspace so we can load it here.\n",
    "If you don't you can check out the save result demo notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "\n",
    "# Connect to the openEO backend and authenticate with EGI Check-In\n",
    "\n",
    "connection = openeo.connect(\"https://openeo-dev.eodc.eu/openeo/1.1.0\")\n",
    "connection = connection.authenticate_oidc(provider_id=\"egi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load a user collection, we have to first find out the collection id, we can do this by listing the stac collections within the workspace using\n",
    "the list_stac_collections(WORKSPACE_NAME) function. This function returns us a list of tuples consisting of the collection_id and the path to the stac collection json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eodc.workspace import CephAdapter, EODC_CEPH_URL\n",
    "\n",
    "# Set these variables to your own.\n",
    "\n",
    "WORKSPACE_NAME = \"\"\n",
    "\n",
    "S3_ENDPOINT = EODC_CEPH_URL\n",
    "S3_ACCESS_KEY = \"\"\n",
    "S3_SECRET_KEY = \"\"\n",
    "\n",
    "adapter: CephAdapter = CephAdapter(S3_ENDPOINT, S3_ACCESS_KEY, S3_SECRET_KEY)\n",
    "\n",
    "collections = adapter.list_stac_collections(WORKSPACE_NAME)\n",
    "\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can either set your collection id manually or set it via the list_stac_collections return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection_id = \"\"\n",
    "\n",
    "collection_id = collections[0][0]\n",
    "\n",
    "collection_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the available STAC items of your given collection beforehand by using the get_stac_items function of the workspace adapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = adapter.get_stac_items(workspace_name=WORKSPACE_NAME, collection_id=collection_id)\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also defaulting to the same spatial_extent and the same temporal_extent as in the save result notebook, feel free to change these to fit your use case.\n",
    "\n",
    "If you want to check the full extent of your user collection you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adapter.get_collection(WORKSPACE_NAME, collection_id).extent.spatial.bboxes) # This prints the maximum bounding box around all items in the STAC collection\n",
    "print(adapter.get_collection(WORKSPACE_NAME, collection_id).extent.temporal.intervals) # This prints the maximum temporal extent of all items in the STAC collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start a job with the corresponding collection_id in the load_collection node, with the workspace property filled out.\n",
    "\n",
    "This will load results from a previous job which we can then further transform and use as we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "process_graph = {\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"process_graph\": {\n",
    "        \"load1\": {\n",
    "            \"process_id\": \"load_collection\",\n",
    "            \"arguments\": {\n",
    "                \"id\": collection_id,\n",
    "                \"properties\": {\"workspace\": WORKSPACE_NAME},\n",
    "                \"spatial_extent\": {\n",
    "                    \"west\": 15,\n",
    "                    \"east\": 48,\n",
    "                    \"south\": 17,\n",
    "                    \"north\": 49,  \n",
    "                },\n",
    "                \"temporal_extent\": [\n",
    "                    \"2019-01-01T00:00:00Z\",\n",
    "                    \"2024-01-08T00:00:00Z\",\n",
    "                ],\n",
    "                \"bands\": [\"raster-result\"],\n",
    "            },\n",
    "        },\n",
    "        \"save2\": {\n",
    "            \"process_id\": \"save_result\",\n",
    "            \"arguments\": {\"data\": {\"from_node\": \"load1\"}, \"format\": \"GTIFF\"},\n",
    "            \"result\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "job = connection.create_job(process_graph=process_graph, title=\"load-from-workspace-job\")\n",
    "job.start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job # Execute this to check on your jobs progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job has run through you can check the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
